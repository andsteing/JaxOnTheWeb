{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1: Converting a simple JAX function\n",
        "\n",
        "This Colab notebook accompanies the [JAX on the Web with TensorFlow.js](https://blog.tensorflow.org/2022/08/JAX-on-the-Web-with-TensorFlow.js.html) blog post."
      ],
      "metadata": {
        "id": "r1MzaCnjuk2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup code"
      ],
      "metadata": {
        "id": "0fIDAAxhwp_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs -q"
      ],
      "metadata": {
        "id": "gbH6Qya1llUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General imports\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import string\n",
        "\n",
        "from IPython.core.display import display, HTML, Javascript\n",
        "import google.colab.html\n",
        "import google.colab.output\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs"
      ],
      "metadata": {
        "id": "2LzWEFOMJlWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a helper function for running inference on a TensorFlow.js model\n",
        "# in Colab directly.\n",
        "\n",
        "_TFJS_SRC_URL = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0'\n",
        "\n",
        "# We have to make HTML resources persistent even if they are not explicitly passed\n",
        "# to JavaScript. Otherwise, they will get garbage collected.\n",
        "global_refs = {}\n",
        "\n",
        "def get_tfjs_predict_fn(model_dir):\n",
        "  \"\"\"Load a TF SavedModel from `model_dir` and return a prediction function.\n",
        "  \n",
        "  Caling the prediction function will run inference on the TFjs model in the\n",
        "  browser.\n",
        "\n",
        "  Arg:\n",
        "    model_dir: Location of the TF SavedModel.\n",
        "  \"\"\"\n",
        "  model_path = os.path.join(model_dir, 'model.json')\n",
        "  ref = google.colab.html.create_resource(filepath=model_path, route=model_path)\n",
        "  weight_path = os.path.join(model_dir, 'group1-shard1of1.bin')\n",
        "\n",
        "  def add_resource(path):\n",
        "    with open(path, 'rb') as f:\n",
        "      return google.colab.html.create_resource(content=f.read(), route=path)\n",
        "\n",
        "  global global_refs\n",
        "  global_refs.update({\n",
        "      p: add_resource(p) for p in glob.glob(os.path.join(model_dir, '*.bin'))})\n",
        "\n",
        "  def call_tfjs(x):\n",
        "    \"\"\"Calls the TFjs model in the browser and returns the output.\"\"\"\n",
        "    print(f'NOTE: Running TFJs inference for model in {model_dir}...')\n",
        "    input_json = json.dumps(jax.tree_map(lambda x: x.tolist(), x))\n",
        "    display(HTML(f'<script src=\"{_TFJS_SRC_URL}\"></script>'))\n",
        "    display(Javascript(string.Template('''\n",
        "      async function getOutput() {\n",
        "        const model = await tf.loadGraphModel('$model_url');\n",
        "        const x = tf.tensor(JSON.parse('$inputs'));\n",
        "        let result = model.predict(x);\n",
        "        console.log(result.shape);\n",
        "        return [await result.data(), result.shape];\n",
        "      }\n",
        "      window.modelOutput = getOutput();\n",
        "    ''').substitute(dict(model_url=ref.url, inputs=input_json))))\n",
        "\n",
        "    output_dict, shape = google.colab.output.eval_js('modelOutput')\n",
        "    return np.array([*output_dict.values()]).reshape(shape).astype(np.float32)\n",
        "  return call_tfjs"
      ],
      "metadata": {
        "id": "f4zZ7H3rHiQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert JAX --> TFjs"
      ],
      "metadata": {
        "id": "eR-ZHtHbwu8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, youâ€™ll convert a few simple JAX functions using `converters.convert_jax()`.\n",
        "\n",
        "The following example uses a single parameter `weight` and implements a function `prod`, which multiplies the input with the parameter (in a real example, `params` will contain the all weights of the modules used in the neural network):"
      ],
      "metadata": {
        "id": "MzO4NSjFtAkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prod(params, xs):\n",
        "  return params['weight'] * xs"
      ],
      "metadata": {
        "id": "wL1M3VmkIrK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'weight': jnp.array([0.5, 1])}\n",
        "xs = np.arange(6).reshape((3, 2))\n",
        "jax_result = prod(params, xs)\n",
        "print(jax_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bV0UZQOuYjl",
        "outputId": "4ea1157c-4a21-4999-f761-cfc6f3c6b076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'example1'\n",
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((3, 2), tf.float32)],\n",
        "    model_dir=model_dir)\n",
        "\n",
        "# Verify the outputs have been written.\n",
        "!ls -l $model_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZERUSTKI7T3",
        "outputId": "b7d69817-a549-4c4a-d45a-2becbc558deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example1/model.json...\n",
            "total 8\n",
            "-rw-r--r-- 1 root root    8 Aug 31 09:07 group1-shard1of1.bin\n",
            "-rw-r--r-- 1 root root 1308 Aug 31 09:07 model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((3, 2), tf.float32)],\n",
        "    model_dir=model_dir)\n",
        "tfjs_predict_fn = get_tfjs_predict_fn(model_dir)\n",
        "print(tfjs_predict_fn(xs))  # Same output as JAX.\n"
      ],
      "metadata": {
        "id": "7vSRk-QdMnCX",
        "colab": {
          "resources": {
            "http://localhost:17469/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:17469/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "dbcde6ad-729b-46cd-d951-bacce24e652d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example1/model.json...\n",
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:17469/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run inference in the browser and verify the results match those of JAX."
      ],
      "metadata": {
        "id": "0lcFumFFCbY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs_predict_fn = get_tfjs_predict_fn(model_dir)\n",
        "tfjs_result = tfjs_predict_fn(xs)\n",
        "assert (jax_result == tfjs_result).all()\n",
        "print('TFjs result:', tfjs_result)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:17469/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:17469/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8PDP4MS1q60D",
        "outputId": "b0e1fb8c-62dd-4d55-de5c-48f3bb919729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:17469/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFjs result: [[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supporting Dynamic Shapes\n",
        "\n",
        "Dynamic shapes do not work in the model we just converted, which can be seen from the error when we try to run inference on the model with a different input shape than `(3, 2)`."
      ],
      "metadata": {
        "id": "WV70yZTWDiUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tfjs_result = tfjs_predict_fn(np.ones((5, 2)))\n",
        "except Exception as e:\n",
        "  print('\\nCAUGHT EXCEPTION:\\n', e)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:17469/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:17469/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "RculLYwp1hAJ",
        "outputId": "bec67d05-6dd4-4ce9-e2e1-e7a147069f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:17469/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CAUGHT EXCEPTION:\n",
            " Error: The shape of dict['xs_0'] provided in model.execute(dict) must be [3,2], but was [5,2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dynamic shapes are supported as usual in Tensorflow by passing the value `None` for the dynamic dimensions in `input_signature`.\n",
        "\n",
        "Additionally, one should pass the argument `polymorphic_shapes` specifying names for dynamic dimensions.\n",
        "\n",
        "Note that [polymorphism](https://github.com/google/jax/tree/main/jax/experimental/jax2tf#shape-polymorphic-conversion) is a term coming from type theory, but here we use it to imply that the function works for multiple related shapes, such as multiple batch sizes. This is necessary for shape checking in the JAX function (see [here](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#shape-polymorphic-conversion) for more documentation on this notation)."
      ],
      "metadata": {
        "id": "3DTzNZwLD7Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'example2'\n",
        "\n",
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((None, 2), tf.float32)],\n",
        "    polymorphic_shapes=['(b, 2)'],\n",
        "    model_dir=model_dir)\n",
        "\n",
        "tfjs_result = get_tfjs_predict_fn(model_dir)(np.arange(10).reshape((5, 2)))\n",
        "print('TFjs result:', tfjs_result)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:17469/example2/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiLTEifSwgeyJzaXplIjogIjIifV19fX0sICJvdXRwdXRzIjogeyJvdXRwdXRfMCI6IHsibmFtZSI6ICJJZGVudGl0eTowIiwgImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIi0xIn0sIHsic2l6ZSI6ICIyIn1dfX19fSwgIm1vZGVsVG9wb2xvZ3kiOiB7Im5vZGUiOiBbeyJuYW1lIjogIlN0YXRlZnVsUGFydGl0aW9uZWRDYWxsL2pheDJ0Zl9wcm9kXy9qaXRfZm5fL0Jyb2FkY2FzdFRvIiwgIm9wIjogIkNvbnN0IiwgImF0dHIiOiB7InZhbHVlIjogeyJ0ZW5zb3IiOiB7ImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjEifSwgeyJzaXplIjogIjIifV19fX0sICJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJ4c18wIiwgIm9wIjogIlBsYWNlaG9sZGVyIiwgImF0dHIiOiB7InNoYXBlIjogeyJzaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICItMSJ9LCB7InNpemUiOiAiMiJ9XX19LCAiZHR5cGUiOiB7InR5cGUiOiAiRFRfRkxPQVQifX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:17469/example2/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Egqrq_zn1kvR",
        "outputId": "47e665bd-52c5-43f3-a0e9-d37c3036ae1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example2/model.json...\n",
            "NOTE: Running TFJs inference for model in example2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:17469/example2/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFjs result: [[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]\n",
            " [3. 7.]\n",
            " [4. 9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tfjs_predict_fn(model_dir)(np.array([[1., 2.]]))"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:17469/example2/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiLTEifSwgeyJzaXplIjogIjIifV19fX0sICJvdXRwdXRzIjogeyJvdXRwdXRfMCI6IHsibmFtZSI6ICJJZGVudGl0eTowIiwgImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIi0xIn0sIHsic2l6ZSI6ICIyIn1dfX19fSwgIm1vZGVsVG9wb2xvZ3kiOiB7Im5vZGUiOiBbeyJuYW1lIjogIlN0YXRlZnVsUGFydGl0aW9uZWRDYWxsL2pheDJ0Zl9wcm9kXy9qaXRfZm5fL0Jyb2FkY2FzdFRvIiwgIm9wIjogIkNvbnN0IiwgImF0dHIiOiB7InZhbHVlIjogeyJ0ZW5zb3IiOiB7ImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjEifSwgeyJzaXplIjogIjIifV19fX0sICJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJ4c18wIiwgIm9wIjogIlBsYWNlaG9sZGVyIiwgImF0dHIiOiB7InNoYXBlIjogeyJzaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICItMSJ9LCB7InNpemUiOiAiMiJ9XX19LCAiZHR5cGUiOiB7InR5cGUiOiAiRFRfRkxPQVQifX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:17469/example2/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Fv8rwIrzX4LB",
        "outputId": "cc178012-c29d-4802-9f57-232918bfc82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:17469/example2/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[1.0, 2.0]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5, 2. ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple arguments and Shape Polymorphism\n",
        "\n",
        "Below we demonstrate with a simple example how to provide multiply arguments with polymorphic shapes. If one now call the model below with different values for the first dimensions, JAX will return a shape error."
      ],
      "metadata": {
        "id": "e0uq1f5eGNUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prod_of_sum(params, x, y):\n",
        "  return params['weight'] * (x + y)\n",
        "\n",
        "jax_result = prod_of_sum(params, xs, xs)\n",
        "model_dir = 'example3'\n",
        "\n",
        "tfjs.converters.convert_jax(\n",
        "    prod_of_sum,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((None, 2), tf.float32),\n",
        "                      tf.TensorSpec((None, 2), tf.float32)],\n",
        "    polymorphic_shapes=['(b, 2)', '(b, 2)'],\n",
        "    model_dir=model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3wR_rDNGLTY",
        "outputId": "c0dd987c-9fa1-49c6-96c7-91d31eb5b7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example3/model.json...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summation `x + y` inside the function `weighted_sum_of_sum` requires the dimensions of both arrays to be equal. So if we pass different variables to the first dimensions in `input_signatures`, we get a shape error. This is very helpful since it allows us to catch these errors before converting."
      ],
      "metadata": {
        "id": "XwBsP1ffLmmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = './example4'\n",
        "\n",
        "try:\n",
        "  tfjs.converters.convert_jax(\n",
        "      prod_of_sum,\n",
        "      params,\n",
        "      input_signatures=[tf.TensorSpec((None, 2), tf.float32),\n",
        "                        tf.TensorSpec((None, 2), tf.float32)],\n",
        "      polymorphic_shapes=['(b, 2)', '(d, 2)'],\n",
        "      model_dir=model_dir)\n",
        "except Exception as e:\n",
        "  print('CAUGHT EXCEPTION:\\n', e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRFdY1etMh35",
        "outputId": "c769ff70-51ff-4448-a684-2f079d20b8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAUGHT EXCEPTION:\n",
            " add got incompatible shapes for broadcasting: (b, 2), (d, 2).\n"
          ]
        }
      ]
    }
  ]
}