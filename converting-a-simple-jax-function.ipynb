{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX on the Web with TensorFlow.js - Converting a simple JAX function",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Converting a simple JAX function\n",
        "\n",
        "This Colab is part of the blogpost\n",
        "[JAX on the Web with TensorFlow.js](https://blog.tensorflow.org/2022/08/JAX-on-the-Web-with-TensorFlow.js.html)"
      ],
      "metadata": {
        "id": "r1MzaCnjuk2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup code"
      ],
      "metadata": {
        "id": "0fIDAAxhwp_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs -q"
      ],
      "metadata": {
        "id": "gbH6Qya1llUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# General imports\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import string\n",
        "\n",
        "from IPython.core.display import display, HTML, Javascript\n",
        "import google.colab.html\n",
        "import google.colab.output\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import tensorflowjs as tfjs"
      ],
      "metadata": {
        "id": "2LzWEFOMJlWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a helper function for running inference on a TensorFlow.js model\n",
        "# in Colab directly.\n",
        "\n",
        "_TFJS_SRC_URL = 'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0'\n",
        "\n",
        "# We have to persistent HTML resources even if they are not explicitly passed\n",
        "# to Javascript. Otherwise, they will get garbage collected.\n",
        "global_refs = {}\n",
        "\n",
        "def get_tfjs_predict_fn(model_dir):\n",
        "  \"\"\"Load a TF SavedModel from `model_dir` and return a prediction function.\n",
        "  \n",
        "  Caling the prediction function will run inference on the TFjs model in the\n",
        "  browser.\n",
        "\n",
        "  Arg:\n",
        "    model_dir: Location of the TF SavedModel.\n",
        "  \"\"\"\n",
        "  model_path = os.path.join(model_dir, 'model.json')\n",
        "  ref = google.colab.html.create_resource(filepath=model_path, route=model_path)\n",
        "  weight_path = os.path.join(model_dir, 'group1-shard1of1.bin')\n",
        "\n",
        "  def add_resource(path):\n",
        "    with open(path, 'rb') as f:\n",
        "      return google.colab.html.create_resource(content=f.read(), route=path)\n",
        "\n",
        "  global global_refs\n",
        "  global_refs.update({\n",
        "      p: add_resource(p) for p in glob.glob(os.path.join(model_dir, '*.bin'))})\n",
        "\n",
        "  def call_tfjs(x):\n",
        "    \"\"\"Calls the TFjs model in the browser and returns the output.\"\"\"\n",
        "    print(f'NOTE: Running TFJs inference for model in {model_dir}...')\n",
        "    input_json = json.dumps(jax.tree_map(lambda x: x.tolist(), x))\n",
        "    display(HTML(f'<script src=\"{_TFJS_SRC_URL}\"></script>'))\n",
        "    display(Javascript(string.Template('''\n",
        "      async function getOutput() {\n",
        "        const model = await tf.loadGraphModel('$model_url');\n",
        "        const x = tf.tensor(JSON.parse('$inputs'));\n",
        "        let result = model.predict(x);\n",
        "        console.log(result.shape);\n",
        "        return [await result.data(), result.shape];\n",
        "      }\n",
        "      window.modelOutput = getOutput();\n",
        "    ''').substitute(dict(model_url=ref.url, inputs=input_json))))\n",
        "\n",
        "    output_dict, shape = google.colab.output.eval_js('modelOutput')\n",
        "    return np.array([*output_dict.values()]).reshape(shape).astype(np.float32)\n",
        "  return call_tfjs"
      ],
      "metadata": {
        "id": "f4zZ7H3rHiQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert JAX --> TFjs"
      ],
      "metadata": {
        "id": "eR-ZHtHbwu8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we will convert a simple JAX function to TFjs using `tfjs.converters.convert_jax`. In this example we use only one type of parameter `weight` and using that we implement a function `prod`, which simply multiplies the inputs."
      ],
      "metadata": {
        "id": "MzO4NSjFtAkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prod(params, xs):\n",
        "  return params['weight'] * xs"
      ],
      "metadata": {
        "id": "wL1M3VmkIrK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'weight': jnp.array([0.5, 1])}\n",
        "xs = np.arange(6).reshape((3, 2))\n",
        "jax_result = prod(params, xs)\n",
        "print(jax_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bV0UZQOuYjl",
        "outputId": "dad6e808-d246-4755-b81f-e6fac7bf6eb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'example1'\n",
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((3, 2), tf.float32)],\n",
        "    model_dir=model_dir)\n",
        "\n",
        "# Verify the outputs have been written.\n",
        "!ls -l $model_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZERUSTKI7T3",
        "outputId": "8eedacdf-c3f2-4aa4-94db-1f976a765a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example1/model.json...\n",
            "total 8\n",
            "-rw-r--r-- 1 root root    8 Aug 29 08:58 group1-shard1of1.bin\n",
            "-rw-r--r-- 1 root root 1308 Aug 29 08:58 model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((3, 2), tf.float32)],\n",
        "    model_dir=model_dir)\n",
        "tfjs_predict_fn = get_tfjs_predict_fn(model_dir)\n",
        "print(tfjs_predict_fn(xs))  # Same output as JAX.\n"
      ],
      "metadata": {
        "id": "7vSRk-QdMnCX",
        "colab": {
          "resources": {
            "http://localhost:21463/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:21463/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2a9ae76a-50cc-4a35-8282-eebe333ae601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example1/model.json...\n",
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:21463/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run inference in the browser and verify the results match those of JAX."
      ],
      "metadata": {
        "id": "0lcFumFFCbY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfjs_predict_fn = get_tfjs_predict_fn(model_dir)\n",
        "tfjs_result = tfjs_predict_fn(xs)\n",
        "assert (jax_result == tfjs_result).all()\n",
        "print('TFjs result:', tfjs_result)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:21463/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:21463/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "8PDP4MS1q60D",
        "outputId": "44117385-d1c2-4987-898c-c03741dc013b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:21463/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFjs result: [[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supporting Dynamic Shapes\n",
        "\n",
        "Dynamic shapes do not work in the model we just converted, which can be seen from the error when we try to run inference on the model with a different input shape than `(3, 2)`."
      ],
      "metadata": {
        "id": "WV70yZTWDiUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tfjs_result = tfjs_predict_fn(np.ones((5, 2)))\n",
        "except Exception as e:\n",
        "  print('\\nCAUGHT EXCEPTION:\\n', e)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:21463/example1/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fSwgIm91dHB1dHMiOiB7Im91dHB1dF8wIjogeyJuYW1lIjogIklkZW50aXR5OjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMyJ9LCB7InNpemUiOiAiMiJ9XX19fX0sICJtb2RlbFRvcG9sb2d5IjogeyJub2RlIjogW3sibmFtZSI6ICJTdGF0ZWZ1bFBhcnRpdGlvbmVkQ2FsbC9qYXgydGZfcHJvZF8vaml0X2ZuXy9Ccm9hZGNhc3RUbyIsICJvcCI6ICJDb25zdCIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAidmFsdWUiOiB7InRlbnNvciI6IHsiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiMSJ9LCB7InNpemUiOiAiMiJ9XX19fX19LCB7Im5hbWUiOiAieHNfMCIsICJvcCI6ICJQbGFjZWhvbGRlciIsICJhdHRyIjogeyJkdHlwZSI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9LCAic2hhcGUiOiB7InNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIjMifSwgeyJzaXplIjogIjIifV19fX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:21463/example1/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "RculLYwp1hAJ",
        "outputId": "ea5a0ca7-1fba-4c14-8031-c3ab8ee434e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example1...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:21463/example1/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0], [1.0, 1.0]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CAUGHT EXCEPTION:\n",
            " Error: The shape of dict['xs_0'] provided in model.execute(dict) must be [3,2], but was [5,2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can implement this by passing value `None` for the dynamic dimensions in `input_signature`. Additionally, we need to pass the argument `polymorphic_shapes` specifying names for polymorphic dimensions. This is necessary for shape checking in the JAX function (see next example). See [here](https://github.com/google/jax/blob/main/jax/experimental/jax2tf/README.md#shape-polymorphic-conversion) for more documentation on this notation."
      ],
      "metadata": {
        "id": "3DTzNZwLD7Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'example2'\n",
        "\n",
        "tfjs.converters.convert_jax(\n",
        "    prod,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((None, 2), tf.float32)],\n",
        "    polymorphic_shapes=['(b, 2)'],\n",
        "    model_dir=model_dir)\n",
        "\n",
        "tfjs_result = get_tfjs_predict_fn(model_dir)(np.arange(10).reshape((5, 2)))\n",
        "print('TFjs result:', tfjs_result)"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:21463/example2/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiLTEifSwgeyJzaXplIjogIjIifV19fX0sICJvdXRwdXRzIjogeyJvdXRwdXRfMCI6IHsibmFtZSI6ICJJZGVudGl0eTowIiwgImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIi0xIn0sIHsic2l6ZSI6ICIyIn1dfX19fSwgIm1vZGVsVG9wb2xvZ3kiOiB7Im5vZGUiOiBbeyJuYW1lIjogIlN0YXRlZnVsUGFydGl0aW9uZWRDYWxsL2pheDJ0Zl9wcm9kXy9qaXRfZm5fL0Jyb2FkY2FzdFRvIiwgIm9wIjogIkNvbnN0IiwgImF0dHIiOiB7ImR0eXBlIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn0sICJ2YWx1ZSI6IHsidGVuc29yIjogeyJkdHlwZSI6ICJEVF9GTE9BVCIsICJ0ZW5zb3JTaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICIxIn0sIHsic2l6ZSI6ICIyIn1dfX19fX0sIHsibmFtZSI6ICJ4c18wIiwgIm9wIjogIlBsYWNlaG9sZGVyIiwgImF0dHIiOiB7InNoYXBlIjogeyJzaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICItMSJ9LCB7InNpemUiOiAiMiJ9XX19LCAiZHR5cGUiOiB7InR5cGUiOiAiRFRfRkxPQVQifX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:21463/example2/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "Egqrq_zn1kvR",
        "outputId": "6903700b-12df-4c82-dd67-37b635039a02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example2/model.json...\n",
            "NOTE: Running TFJs inference for model in example2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:21463/example2/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFjs result: [[0. 1.]\n",
            " [1. 3.]\n",
            " [2. 5.]\n",
            " [3. 7.]\n",
            " [4. 9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_tfjs_predict_fn(model_dir)(np.array([[1., 2.]]))"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:21463/example2/model.json": {
              "data": "eyJmb3JtYXQiOiAiZ3JhcGgtbW9kZWwiLCAiZ2VuZXJhdGVkQnkiOiAiMi44LjIiLCAiY29udmVydGVkQnkiOiAiVGVuc29yRmxvdy5qcyBDb252ZXJ0ZXIgdjMuMjAuMCIsICJzaWduYXR1cmUiOiB7ImlucHV0cyI6IHsieHNfMCI6IHsibmFtZSI6ICJ4c18wOjAiLCAiZHR5cGUiOiAiRFRfRkxPQVQiLCAidGVuc29yU2hhcGUiOiB7ImRpbSI6IFt7InNpemUiOiAiLTEifSwgeyJzaXplIjogIjIifV19fX0sICJvdXRwdXRzIjogeyJvdXRwdXRfMCI6IHsibmFtZSI6ICJJZGVudGl0eTowIiwgImR0eXBlIjogIkRUX0ZMT0FUIiwgInRlbnNvclNoYXBlIjogeyJkaW0iOiBbeyJzaXplIjogIi0xIn0sIHsic2l6ZSI6ICIyIn1dfX19fSwgIm1vZGVsVG9wb2xvZ3kiOiB7Im5vZGUiOiBbeyJuYW1lIjogIlN0YXRlZnVsUGFydGl0aW9uZWRDYWxsL2pheDJ0Zl9wcm9kXy9qaXRfZm5fL0Jyb2FkY2FzdFRvIiwgIm9wIjogIkNvbnN0IiwgImF0dHIiOiB7ImR0eXBlIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn0sICJ2YWx1ZSI6IHsidGVuc29yIjogeyJkdHlwZSI6ICJEVF9GTE9BVCIsICJ0ZW5zb3JTaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICIxIn0sIHsic2l6ZSI6ICIyIn1dfX19fX0sIHsibmFtZSI6ICJ4c18wIiwgIm9wIjogIlBsYWNlaG9sZGVyIiwgImF0dHIiOiB7InNoYXBlIjogeyJzaGFwZSI6IHsiZGltIjogW3sic2l6ZSI6ICItMSJ9LCB7InNpemUiOiAiMiJ9XX19LCAiZHR5cGUiOiB7InR5cGUiOiAiRFRfRkxPQVQifX19LCB7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIiwgIm9wIjogIk11bCIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAieHNfMCJdLCAiYXR0ciI6IHsiVCI6IHsidHlwZSI6ICJEVF9GTE9BVCJ9fX0sIHsibmFtZSI6ICJJZGVudGl0eSIsICJvcCI6ICJJZGVudGl0eSIsICJpbnB1dCI6IFsiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vTXVsIl0sICJhdHRyIjogeyJUIjogeyJ0eXBlIjogIkRUX0ZMT0FUIn19fV0sICJsaWJyYXJ5Ijoge30sICJ2ZXJzaW9ucyI6IHsicHJvZHVjZXIiOiA5ODd9fSwgIndlaWdodHNNYW5pZmVzdCI6IFt7InBhdGhzIjogWyJncm91cDEtc2hhcmQxb2YxLmJpbiJdLCAid2VpZ2h0cyI6IFt7Im5hbWUiOiAiU3RhdGVmdWxQYXJ0aXRpb25lZENhbGwvamF4MnRmX3Byb2RfL2ppdF9mbl8vQnJvYWRjYXN0VG8iLCAic2hhcGUiOiBbMSwgMl0sICJkdHlwZSI6ICJmbG9hdDMyIn1dfV19",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/json"
                ]
              ],
              "status": 200,
              "status_text": ""
            },
            "http://localhost:21463/example2/group1-shard1of1.bin": {
              "data": "AAAAPwAAgD8=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/octet-stream"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Fv8rwIrzX4LB",
        "outputId": "fb6af04a-3cb4-4537-a0b2-7f1001297754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOTE: Running TFJs inference for model in example2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "      async function getOutput() {\n",
              "        const model = await tf.loadGraphModel('https://localhost:21463/example2/model.json');\n",
              "        const x = tf.tensor(JSON.parse('[[1.0, 2.0]]'));\n",
              "        let result = model.predict(x);\n",
              "        console.log(result.shape);\n",
              "        return [await result.data(), result.shape];\n",
              "      }\n",
              "      window.modelOutput = getOutput();\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5, 2. ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple arguments and Shape Polymorphism\n",
        "\n",
        "Below we demonstrate with a simple example how to provide multiply arguments with polymorphic shapes. If one now call the model below with different values for the first dimensions, JAX will return a shape error."
      ],
      "metadata": {
        "id": "e0uq1f5eGNUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prod_of_sum(params, x, y):\n",
        "  return params['weight'] * (x + y)\n",
        "\n",
        "jax_result = prod_of_sum(params, xs, xs)\n",
        "model_dir = 'example3'\n",
        "\n",
        "tfjs.converters.convert_jax(\n",
        "    prod_of_sum,\n",
        "    params,\n",
        "    input_signatures=[tf.TensorSpec((None, 2), tf.float32),\n",
        "                      tf.TensorSpec((None, 2), tf.float32)],\n",
        "    polymorphic_shapes=['(b, 2)', '(b, 2)'],\n",
        "    model_dir=model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3wR_rDNGLTY",
        "outputId": "47eb9570-f08f-4b83-824b-9e32e37e8cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n",
            "WARNING:tensorflow:@custom_gradient grad_fn has 'variables' in signature, but no ResourceVariables were used on the forward pass.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing weight file example3/model.json...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The summation `x + y` inside the function `weighted_sum_of_sum` requires the dimensions of both arrays to be equal. So if we pass different variables to the first dimensions in `input_signatures`, we get a shape error. This is very helpful since it allows us to catch these errors before converting."
      ],
      "metadata": {
        "id": "XwBsP1ffLmmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = './example4'\n",
        "\n",
        "try:\n",
        "  tfjs.converters.convert_jax(\n",
        "      prod_of_sum,\n",
        "      params,\n",
        "      input_signatures=[tf.TensorSpec((None, 2), tf.float32),\n",
        "                        tf.TensorSpec((None, 2), tf.float32)],\n",
        "      polymorphic_shapes=['(b, 2)', '(d, 2)'],\n",
        "      model_dir=model_dir)\n",
        "except Exception as e:\n",
        "  print('CAUGHT EXCEPTION:\\n', e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRFdY1etMh35",
        "outputId": "1aa1ed55-8fe4-4db5-f628-fa7a2b37dff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CAUGHT EXCEPTION:\n",
            " add got incompatible shapes for broadcasting: (b, 2), (d, 2).\n"
          ]
        }
      ]
    }
  ]
}